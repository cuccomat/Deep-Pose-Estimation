{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ON_COLAB = False\n",
    "\n",
    "if ON_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.0.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Requirement already satisfied: torchvision in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: torch==1.12.1 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (4.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.21.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Requirement already satisfied: matplotlib in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.21.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.36.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Requirement already satisfied: pandas in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.21.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.21.1-py3-none-any.whl (3.4 MB)\n",
      "     ---------------------------------------- 3.4/3.4 MB 15.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imageio) (1.21.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imageio) (9.0.0)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.21.1\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Collecting trimesh\n",
      "  Downloading trimesh-3.13.5-py3-none-any.whl (660 kB)\n",
      "     -------------------------------------- 660.9/660.9 kB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trimesh) (1.21.4)\n",
      "Installing collected packages: trimesh\n",
      "Successfully installed trimesh-3.13.5\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Collecting pyrender\n",
      "  Using cached pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
      "Collecting PyOpenGL==3.1.0\n",
      "  Using cached PyOpenGL-3.1.0.zip (2.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting networkx\n",
      "  Downloading networkx-2.8.5-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyglet>=1.4.10 in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrender) (2.0.dev13)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.9.0-cp310-cp310-win_amd64.whl (38.6 MB)\n",
      "     --------------------------------------- 38.6/38.6 MB 16.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrender) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrender) (1.21.4)\n",
      "Requirement already satisfied: trimesh in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrender) (3.13.5)\n",
      "Collecting freetype-py\n",
      "  Using cached freetype_py-2.3.0-py3-none-win_amd64.whl (772 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrender) (9.0.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\39331\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrender) (2.21.1)\n",
      "Building wheels for collected packages: PyOpenGL\n",
      "  Building wheel for PyOpenGL (setup.py): started\n",
      "  Building wheel for PyOpenGL (setup.py): still running...\n",
      "  Building wheel for PyOpenGL (setup.py): finished with status 'done'\n",
      "  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1749292 sha256=b0119aeff8a7073e7d34f701c9e21fe13195c7c8eeeb10e2da20e0339c4702d4\n",
      "  Stored in directory: c:\\users\\39331\\appdata\\local\\pip\\cache\\wheels\\a1\\3c\\d2\\1f9533f908d86176637521e533c6cdb2d4e48b59003b5c3f19\n",
      "Successfully built PyOpenGL\n",
      "Installing collected packages: PyOpenGL, scipy, networkx, freetype-py, pyrender\n",
      "Successfully installed PyOpenGL-3.1.0 freetype-py-2.3.0 networkx-2.8.5 pyrender-0.1.45 scipy-1.9.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\39331\\Documents\\Final Year Project\\Deep-Pose-Estimation\\baseline\\get_pose_with_PnP.ipynb Cella 2\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=33'>34</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=34'>35</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=35'>36</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=36'>37</a>\u001b[0m \u001b[39m'''!pip install wandb\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=37'>38</a>\u001b[0m \u001b[39mimport wandb\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=38'>39</a>\u001b[0m \u001b[39m!wandb login --relogin'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=39'>40</a>\u001b[0m \u001b[39m# api_key = f2c3bd208d418cf11dcc2c2cbf5e4bc0fc104421\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=40'>41</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000001?line=41'>42</a>\u001b[0m \u001b[39m# set the seed for reproducibility\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "# torch\n",
    "!pip install torch\n",
    "import torch\n",
    "from torch.nn import Conv2d, MaxPool2d\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import sampler\n",
    "!pip install torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "# other\n",
    "import sys\n",
    "sys.path.append('drive/Othercomputers/Il mio laptop/Deep-Pose-Estimation/baseline/')\n",
    "import params2\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "from pathlib import Path\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "!pip install imageio\n",
    "import imageio\n",
    "from csv import writer\n",
    "from csv import reader\n",
    "from PIL import Image\n",
    "!pip install trimesh\n",
    "import trimesh\n",
    "!pip install pyrender\n",
    "import pyrender\n",
    "if ON_COLAB:\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    !pip install tqdm\n",
    "    from tqdm import tqdm\n",
    "'''!pip install wandb\n",
    "import wandb\n",
    "!wandb login --relogin'''\n",
    "# api_key = f2c3bd208d418cf11dcc2c2cbf5e4bc0fc104421\n",
    "\n",
    "# set the seed for reproducibility\n",
    "rng_seed = 90\n",
    "torch.manual_seed(rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = params.Parameters()\n",
    "print(par.epochs)\n",
    "print(par.resume)\n",
    "print(par.run_id)\n",
    "print(par.batch_size)\n",
    "print(par.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\" #opengl seems to only work with TPU\n",
    "!PYOPENGL_PLATFORM=egl python -c \"from OpenGL import EGL\"\n",
    "print(os.environ['PYOPENGL_PLATFORM']) \n",
    "\n",
    "import OpenGL.GL as gl\n",
    "print(gl.glGetString(gl.GL_VERSION))\n",
    "print(gl.glGetString(gl.GL_VENDOR)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt_path = par.txt_path\n",
    "txt_path = 'drive/Othercomputers/Il mio laptop/Deep-Pose-Estimation/baseline/poses_equatoriale_txt'\n",
    "\n",
    "def get_nth_line(fobj, n):\n",
    "    for i in range(n):\n",
    "        next(fobj)\n",
    "    return next(fobj)\n",
    "\n",
    "columns = ['id', 'x', 'y', 'z', 'roll', 'pitch', 'yaw']\n",
    "\n",
    "with open('drive/Othercomputers/Il mio laptop/Deep-Pose-Estimation/baseline/poses_equatoriale.csv', 'w') as f_object:\n",
    "    writer_object = writer(f_object)\n",
    "    writer_object.writerow(columns)\n",
    "    for f in Path(txt_path).iterdir():\n",
    "        id = int(str(f).split('/')[-1].split('.txt')[0]) \n",
    "        file = open(f)\n",
    "        line4 = get_nth_line(file, 4).split('\\n')[0]\n",
    "        line_splitted = line4.split(' ')\n",
    "        writer_object.writerow([id] + line_splitted)\n",
    "    f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\39331\\Documents\\Final Year Project\\Deep-Pose-Estimation\\baseline\\get_pose_with_PnP.ipynb Cella 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPoseDataset\u001b[39;00m(Dataset):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000007?line=2'>3</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, csv_file, root_dir):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000007?line=3'>4</a>\u001b[0m         \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000007?line=4'>5</a>\u001b[0m \u001b[39m        Args:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000007?line=5'>6</a>\u001b[0m \u001b[39m            csv_file (string): Path to the csv file with annotations.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000007?line=8'>9</a>\u001b[0m \u001b[39m                on a sample.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/39331/Documents/Final%20Year%20Project/Deep-Pose-Estimation/baseline/get_pose_with_PnP.ipynb#ch0000007?line=9'>10</a>\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class PoseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        poses = pd.read_csv(csv_file)\n",
    "        self.poses = poses#.sort_values(by=[\"id\"])\n",
    "        self.root_dir = root_dir\n",
    "  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.poses)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = os.path.join(self.root_dir,\n",
    "                                str(self.poses.iloc[idx, 0]) + '-N_.png')\n",
    "        \n",
    "        img = imageio.imread(img_path, ignoregamma = True)\n",
    "        rgb_img = img[:,:,:3]\n",
    "        img_tensor = torch.tensor(rgb_img)/255.0\n",
    "        img_tensor = np.transpose(img_tensor, (2, 0, 1))\n",
    "        \n",
    "        img_downsampled = F.interpolate(img_tensor, scale_factor = 0.25)\n",
    "        img_downsampled = np.transpose(img_downsampled, (0, 2, 1))\n",
    "        img_downsampled = F.interpolate(img_downsampled, scale_factor = 0.25)\n",
    "        img_downsampled = np.transpose(img_downsampled, (0, 2, 1))\n",
    "\n",
    "        #pose = self.poses.iloc[idx, 1:]\n",
    "        pose = np.array([pose])\n",
    "        pose =  pose.reshape(6)\n",
    "        return img_downsampled, pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pose(model_path, pose, img):\n",
    "\n",
    "    tm = trimesh.load(model_path) \n",
    "    mesh = pyrender.Mesh.from_trimesh(tm)\n",
    "    pose = torch.squeeze(pose, dim=0) \n",
    "    print('xyz_rpy', pose.cpu().numpy().shape)\n",
    "    tx, ty, tz, rx, ry, rz = pose.cpu().numpy()\n",
    "    print('xyz_rpy', pose)\n",
    "\n",
    "    r = R.from_euler('xyz',[rx, ry, rz], degrees=True)\n",
    "    #r = R.from_euler('zyx',[rx, ry, rz], degrees=True)\n",
    "\n",
    "    Twc = np.eye(4)\n",
    "    Twc[:3,:3] = r.as_matrix()\n",
    "    Twc[:3,3] = np.array([tx, ty, tz])\n",
    "\n",
    "    Twc [0,1] *= -1\n",
    "    Twc [1,0] *= -1\n",
    "    Twc [1,2] *= -1\n",
    "    Twc [2,1] *= -1\n",
    "\n",
    "    Twc [0,3] *= -1\n",
    "\n",
    "    print('Twc', Twc)\n",
    "\n",
    "    im_width, im_height = (1024,1024)\n",
    "    camK = np.array([[886.81,0.0,512.0],[0.0,886.81,512.0],[0.0,0.0,1.0]])\n",
    "\n",
    "    camera = pyrender.IntrinsicsCamera(camK[0,0],camK[1,1],\n",
    "                                        camK[0,2],camK[1,2], zfar = 500.0)\n",
    "\n",
    "    scene=pyrender.Scene()\n",
    "    scene.add(camera,pose=Twc)\n",
    "    scene.add(mesh,pose=np.eye(4))\n",
    "    r = pyrender.OffscreenRenderer(im_width, im_height)\n",
    "    color,depth = r.render(scene)\n",
    "\n",
    "    # Flip y in image space\n",
    "    color = color[::-1,:,:]\n",
    "    depth = depth[::-1,:]\n",
    "\n",
    "    # Flip x in image space\n",
    "    color = color[:,::-1,:]\n",
    "    depth = depth[:,::-1]\n",
    "\n",
    "    # Overlap the two images for comparision\n",
    "    figure = plt.figure(figsize = (10, 10))\n",
    "    #plt.imshow(img, alpha = 1.0, cmap = plt.cm.gray)\n",
    "    plt.imshow(depth, cmap = plt.cm.gray_r)\n",
    "    print('depth', depth)\n",
    "    wandb.log({\"Test samples overlapping pose\": figure})\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_dataset = PoseDataset(csv_file = 'drive/Othercomputers/Il mio laptop/Deep-Pose-Estimation/baseline/poses_equatoriale.csv',\n",
    "                           root_dir='drive/Othercomputers/Il mio laptop/Deep-Pose-Estimation/baseline/RGB_images_equatoriale')\n",
    "print(len(pose_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train val test split\n",
    "n = len(pose_dataset)\n",
    "n_1 = int(n/10)\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "    pose_dataset, [n-(2*n_1), n_1, n_1])\n",
    "\n",
    "print(len(train_set), len(val_set), len(test_set))\n",
    "\n",
    "loader_train = DataLoader(train_set, batch_size=par.batch_size, shuffle=par.shuffle, num_workers=2)\n",
    "loader_val = DataLoader(val_set, batch_size=par.batch_size, shuffle=par.shuffle, num_workers=2)\n",
    "loader_test = DataLoader(test_set, batch_size=par.batch_size, shuffle=par.shuffle, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "print(len(loader_train))\n",
    "for t, (x, y) in enumerate(tqdm(loader_train, leave=False)):\n",
    "    transform = transforms.ToPILImage()\n",
    "    x = torch.squeeze(x, dim=0) \n",
    "    image_upsampled = F.interpolate(x, scale_factor = 2)\n",
    "    image_upsampled = np.transpose(image_upsampled, (0, 2, 1))\n",
    "    image_upsampled = F.interpolate(image_upsampled, scale_factor = 2)\n",
    "    image_upsampled = np.transpose(image_upsampled, (0, 2, 1))\n",
    "    image_upsampled = F.interpolate(image_upsampled, scale_factor = 2)\n",
    "    image_upsampled = np.transpose(image_upsampled, (0, 2, 1))\n",
    "    image_upsampled = F.interpolate(image_upsampled, scale_factor = 2)\n",
    "    image_upsampled = np.transpose(image_upsampled, (0, 2, 1))\n",
    "    image = transform(image_upsampled)\n",
    "    #img_ddble = cv2.resize(img, (0, 0), fx=0.5, fy=0.5)\n",
    "    pose = print_pose(model_path=par.tm_path, pose=y, img=image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f9ed9a95e24040784a2605efde89aae17bf486bbb917acb66e2378dc50ed1b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
